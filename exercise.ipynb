{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRymAZnkc8ATnzN5izkPat",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vigyat1/portfolio/blob/main/exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python numpy scipy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4AIfJXGm2xC",
        "outputId": "f29a7149-e76e-45bb-9ae5-ade1a749d5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.12/dist-packages (0.10.21)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pose_detector.py\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class PoseDetector:\n",
        "    def __init__(self, static_image_mode=False, smooth=True):\n",
        "        self.mp_pose = mp.solutions.pose\n",
        "        self.pose = self.mp_pose.Pose(\n",
        "            static_image_mode=static_image_mode,\n",
        "            model_complexity=1,\n",
        "            smooth_landmarks=smooth,\n",
        "            min_detection_confidence=0.5,\n",
        "            min_tracking_confidence=0.5,\n",
        "        )\n",
        "        self.mp_draw = mp.solutions.drawing_utils\n",
        "\n",
        "    def detect_pose(self, frame):\n",
        "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = self.pose.process(rgb)\n",
        "        return results\n",
        "\n",
        "    def extract_keypoints(self, results, width, height):\n",
        "        if not results.pose_landmarks:\n",
        "            return None\n",
        "\n",
        "        points = []\n",
        "        for lm in results.pose_landmarks.landmark:\n",
        "            points.append([int(lm.x * width), int(lm.y * height), lm.visibility])\n",
        "        return np.array(points)\n",
        "\n",
        "    def draw_landmarks(self, frame, results):\n",
        "        if results.pose_landmarks:\n",
        "            self.mp_draw.draw_landmarks(\n",
        "                frame,\n",
        "                results.pose_landmarks,\n",
        "                self.mp_pose.POSE_CONNECTIONS\n",
        "            )\n",
        "        return frame\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iahO2i6tnNlG",
        "outputId": "957c1c1b-5ba4-435c-f679-ffc501111ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting pose_detector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile angle_utils.py\n",
        "import numpy as np\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "\n",
        "def calculate_angle(a, b, c):\n",
        "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
        "    ba = a - b\n",
        "    bc = c - b\n",
        "\n",
        "    cos_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-8)\n",
        "    angle = np.degrees(np.arccos(np.clip(cos_angle, -1.0, 1.0)))\n",
        "    return angle\n",
        "\n",
        "\n",
        "def smooth_signal(values, window=7, poly=3):\n",
        "    if len(values) < window:\n",
        "        return values\n",
        "    return savgol_filter(values, window, poly)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4NguQlIqDHA",
        "outputId": "eea31668-fb04-4c53-b1c9-e73422d55f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting angle_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile rules.py\n",
        "from angle_utils import calculate_angle\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class FormRules:\n",
        "    def __init__(self):\n",
        "        self.feedback = {\"elbow\": \"\", \"wrist\": \"\", \"back\": \"\"}\n",
        "\n",
        "    def check_elbow_angle(self, keypoints, side=\"left\"):\n",
        "        SHOULDER = 11 if side == \"left\" else 12\n",
        "        ELBOW = 13 if side == \"left\" else 14\n",
        "        WRIST = 15 if side == \"left\" else 16\n",
        "\n",
        "        s = keypoints[SHOULDER][:2]\n",
        "        e = keypoints[ELBOW][:2]\n",
        "        w = keypoints[WRIST][:2]\n",
        "\n",
        "        angle = calculate_angle(s, e, w)\n",
        "\n",
        "        if angle > 150:\n",
        "            self.feedback[\"elbow\"] = \"Arm extended (down phase)\"\n",
        "        elif 40 <= angle <= 70:\n",
        "            self.feedback[\"elbow\"] = \"Good curl\"\n",
        "        else:\n",
        "            self.feedback[\"elbow\"] = \"Incorrect elbow angle\"\n",
        "\n",
        "        return angle\n",
        "\n",
        "    def check_wrist_alignment(self, keypoints, side=\"left\"):\n",
        "        SHOULDER = 11 if side == \"left\" else 12\n",
        "        WRIST = 15 if side == \"left\" else 16\n",
        "\n",
        "        sh = keypoints[SHOULDER][:2]\n",
        "        wr = keypoints[WRIST][:2]\n",
        "\n",
        "        diff = abs(sh[1] - wr[1])\n",
        "\n",
        "        if diff < 40:\n",
        "            self.feedback[\"wrist\"] = \"Good wrist alignment\"\n",
        "        else:\n",
        "            self.feedback[\"wrist\"] = \"Adjust wrist height\"\n",
        "\n",
        "        return diff\n",
        "\n",
        "    def check_back_angle(self, keypoints):\n",
        "        left_sh = keypoints[11][:2]\n",
        "        left_hip = keypoints[23][:2]\n",
        "\n",
        "        dy = abs(left_sh[1] - left_hip[1])\n",
        "        dx = abs(left_sh[0] - left_hip[0])\n",
        "        angle = np.degrees(np.arctan2(dx, dy))\n",
        "\n",
        "        if angle < 15:\n",
        "            self.feedback[\"back\"] = \"Back straight\"\n",
        "        else:\n",
        "            self.feedback[\"back\"] = \"Torso leaning\"\n",
        "\n",
        "        return angle\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9mi9gIvqITU",
        "outputId": "8dad251a-f6d0-42bd-cbc2-0b9b3603c819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting rules.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile video_processor.py\n",
        "import cv2\n",
        "from pose_detector import PoseDetector\n",
        "from rules import FormRules\n",
        "from angle_utils import smooth_signal\n",
        "\n",
        "\n",
        "class VideoProcessor:\n",
        "    def __init__(self, input_path, output_path):\n",
        "        self.detector = PoseDetector()\n",
        "        self.rules = FormRules()\n",
        "        self.input_path = input_path\n",
        "        self.output_path = output_path\n",
        "        self.elbow_angles = []\n",
        "\n",
        "    def process_video(self):\n",
        "        cap = cv2.VideoCapture(self.input_path)\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "        writer = cv2.VideoWriter(\n",
        "            self.output_path,\n",
        "            cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "            fps,\n",
        "            (width, height)\n",
        "        )\n",
        "\n",
        "        while True:\n",
        "            success, frame = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "\n",
        "            results = self.detector.detect_pose(frame)\n",
        "            keypoints = self.detector.extract_keypoints(results, width, height)\n",
        "\n",
        "            if keypoints is not None:\n",
        "                elbow_angle = self.rules.check_elbow_angle(keypoints)\n",
        "                self.rules.check_wrist_alignment(keypoints)\n",
        "                self.rules.check_back_angle(keypoints)\n",
        "\n",
        "                frame = self.detector.draw_landmarks(frame, results)\n",
        "\n",
        "                y = 30\n",
        "                for rule, msg in self.rules.feedback.items():\n",
        "                    cv2.putText(frame, f\"{rule}: {msg}\", (20, y),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "                    y += 30\n",
        "\n",
        "            writer.write(frame)\n",
        "\n",
        "        cap.release()\n",
        "        writer.release()\n",
        "        print(\"Processing Finished!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el6C0FJDqM4x",
        "outputId": "545326f5-3dc8-405e-f103-09b00d0f296c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting video_processor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "from video_processor import VideoProcessor\n",
        "\n",
        "def main():\n",
        "    input_video = \"input_video.mp4\"   # file you uploaded\n",
        "    output_video = \"output_with_feedback.mp4\"\n",
        "\n",
        "    processor = VideoProcessor(input_video, output_video)\n",
        "    processor.process_video()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7XzUeXVqS4h",
        "outputId": "a2064f51-d57e-4233-f0d7-f8572dedc13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUPbF4E3qahl",
        "outputId": "248efc09-f0e5-4a98-ad0e-0aa6c6b25546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-12 08:30:52.494017: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765528252.523013    6094 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765528252.538883    6094 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765528252.576482    6094 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765528252.576540    6094 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765528252.576546    6094 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765528252.576558    6094 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-12 08:30:52.586543: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.12/dist-packages/jaxlib/plugin_support.py:71: RuntimeWarning: JAX plugin jax_cuda12_plugin version 0.7.2 is installed, but it is not compatible with the installed jaxlib version 0.7.1, so it will not be used.\n",
            "  warnings.warn(\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "W0000 00:00:1765528268.259876    6206 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "W0000 00:00:1765528268.331634    6206 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "W0000 00:00:1765528268.363254    6207 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
            "Processing Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"output_with_feedback.mp4\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mrk3mAxzq4uZ",
        "outputId": "eef77996-30ae-4a83-f9f8-9382dd0eddc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f4674a7e-4fd0-4218-aebc-499670581695\", \"output_with_feedback.mp4\", 38162530)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}